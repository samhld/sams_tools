cpu = from(bucket: "telegraf/two_weeks")
  |> range(start: -5m, stop: -4m)
  |> filter(fn: (r) => r._measurement == "cpu" and (r._field == "usage_system" or r._field == "usage_user"))
  |> filter(fn: (r) => r.host =~ /data/)
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> rename(columns: {usage_user: "cpu_usage_user", usage_system: "cpu_usage_system"})
  |> drop(columns: ["_measurement","_start","_stop","cpu"])

mem = from(bucket: "telegraf/two_weeks")
  |> range(start: -5m, stop: -4m)
  |> filter(fn: (r) => r._measurement == "mem" and (r._field == "used" or r._field == "available"))
  |> filter(fn: (r) => r.host =~ /data/)
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> rename(columns: {used: "mem_used", available: "mem_available"})
  |> drop(columns: ["_measurement","_start","_stop"])

pointReqs = from(bucket: "telegraf/two_weeks")
  |> range(start: -5m, stop: -4m)
  |> filter(fn: (r) => r._measurement == "influxdb_write")
  |> filter(fn: (r) => r._field == "pointReq")
  |> filter(fn: (r) => r.host =~ /data/ and r.host !~ /data-1/)
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> derivative(unit: 1m, nonNegative: true, columns: ["pointReq"], timeColumn: "_time")
  |> rename(columns: {pointReq: "point_req_per_min"})
  |> drop(columns: ["_measurement","_start","_stop","url"])

system = from(bucket: "telegraf/two_weeks")
  |> range(start: -5m, stop: -4m)
  |> filter(fn: (r) => r._measurement == "system" and (r._field == "load1" or r._field == "load15" or r._field == "load5" or r._field == "n_cpus"))
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> drop(columns: ["_measurement","_start","_stop"])

// needs a sum per disk name per host -- unable to so far because differing row counts per table which will skew sum
diskio = from(bucket: "telegraf/two_weeks")
  |> range(start: -5m, stop: -4m)
  |> filter(fn: (r) => r._measurement == "diskio" and (r._field == "reads" or r._field == "writes" or r._field == "write_bytes" or r._field == "read_bytes"))
  |> filter(fn: (r) => r.host =~ /data/ and r.host =~ /data/)
  |> difference(nonNegative: false, columns: ["_value"])
  |> group(columns: ["_time","_value","name"], mode: "except")
  |> aggregateWindow(every: 10s, fn: sum)
  |> filter(fn: (r) => exists r._value)
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> drop(columns: ["_measurement","_start","_stop"])

queries = from(bucket: "telegraf/two_weeks")
  |> range(start: -5m, stop: -4m)
  |> filter(fn: (r) => r._measurement == "influxdb_queryExecutor" and (r._field == "queriesExecuted"))
  |> derivative(unit: 1s, nonNegative: true, columns: ["_value"], timeColumn: "_time")
  |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
  |> rename(columns: {queriesExecuted: "queries_per_sec"})
  |> drop(columns: ["_measurement","url","_start","_stop"])

cpu_mem = join(tables: {d1: cpu, d2: mem}, on: ["_time","cluster_id","host"])
points_cpu_mem = join(tables: {d1: cpu_mem, d2: pointReqs}, on: ["_time","cluster_id","host"])
sys_points_cpu_mem = join(tables: {d1: points_cpu_mem, d2: system}, on: ["_time","cluster_id","host"])
disk_sys_points_cpu_mem = join(tables: {d1: sys_points_cpu_mem, d2: diskio}, on: ["_time","cluster_id","host"])
queries_disk_sys_points_cpu_mem = join(tables: {d1: disk_sys_points_cpu_mem, d2: queries}, on: ["_time","cluster_id","host"])
queries_disk_sys_points_cpu_mem